{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ThinkBayes - Chapter 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardoV94/ThinkBayesPymc3/blob/master/ThinkBayes_Chapter_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVPW-yWN8sm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pymc3 as pm\n",
        "import matplotlib.pyplot as plt\n",
        "import theano.tensor as tt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcxoCWIdWgVO",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 The cookie problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS8H6smj8xkR",
        "colab_type": "code",
        "outputId": "9b54378d-c359-4f72-a2a7-fe2bb30b7621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "with pm.Model() as m_1_4:\n",
        "    obs = pm.Data('data', [True])\n",
        "\n",
        "    # Prior \n",
        "    bowl1 = pm.Bernoulli('bowl1', 1/2)\n",
        "\n",
        "    # Conditional probabality / Likelihood\n",
        "    p_vanilla = pm.math.switch(bowl1, 3/4, 1/2)\n",
        "    vanilla = pm.Bernoulli('vanilla', p_vanilla, observed=obs)\n",
        "\n",
        "    trace_m_1_4 = pm.sample(2000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential sampling (2 chains in 1 job)\n",
            "BinaryGibbsMetropolis: [bowl1]\n",
            "100%|██████████| 2500/2500 [00:01<00:00, 2320.75it/s]\n",
            "100%|██████████| 2500/2500 [00:00<00:00, 6127.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtynS_L0--Zd",
        "colab_type": "code",
        "outputId": "96eb4f9c-a2f9-4694-cac3-91c411f51a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trace_m_1_4['bowl1'].mean(), 3/5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.60325, 0.6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0rQ4Yz7XOsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "92739bee-4a69-4d88-b6a8-894617818e02"
      },
      "source": [
        "# Now taking an extra Chocolate and Vanilla cookie\n",
        "with m_1_4:\n",
        "    pm.set_data({'data': [True, False, True]})\n",
        "    _trace_m_1_4 = pm.sample(2000)\n",
        "_trace_m_1_4['bowl1'].mean()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential sampling (2 chains in 1 job)\n",
            "BinaryGibbsMetropolis: [bowl1]\n",
            "100%|██████████| 2500/2500 [00:00<00:00, 5261.35it/s]\n",
            "100%|██████████| 2500/2500 [00:00<00:00, 5265.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5305"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36a_oqHlWmlb",
        "colab_type": "text"
      },
      "source": [
        "## 1.6 The M&M problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwquEf8igxgj",
        "colab_type": "code",
        "outputId": "d9694c08-ed59-4dbc-c724-74e29220dbb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "with pm.Model() as m_1_6:\n",
        "    obs1 = pm.Data('data1', [0])\n",
        "    obs2 = pm.Data('data2', [1])\n",
        "\n",
        "    # Prior \n",
        "    bag94_first = pm.Bernoulli('bag94_first', p=1/2)\n",
        "    bag94 = [20, 10, 0]\n",
        "    bag96 = [14, 20, 24]\n",
        "\n",
        "    # Conditional probabality / Likelihood\n",
        "    p_bags = pm.math.switch(bag94_first, [bag94, bag96], [bag96, bag94])\n",
        "    bag1 = pm.Categorical('bag1', p=p_bags[0], observed=obs1)\n",
        "    bag2 = pm.Categorical('bag2', p=p_bags[1], observed=obs2)\n",
        "\n",
        "    trace_m_1_6 = pm.sample(200)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only 200 samples in chain.\n",
            "Sequential sampling (2 chains in 1 job)\n",
            "BinaryGibbsMetropolis: [bag94_first]\n",
            "100%|██████████| 700/700 [00:00<00:00, 4851.42it/s]\n",
            "100%|██████████| 700/700 [00:00<00:00, 4549.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DQUoZNBS_I",
        "colab_type": "code",
        "outputId": "7483de45-b30b-435a-b976-6d6cded205b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trace_m_1_6['bag94_first'].mean(), 20/27"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.74, 0.7407407407407407)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDVDMZ29Y28O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a346b53d-ebd2-4208-da7f-1688319c9dc2"
      },
      "source": [
        "# Now taking a blue M&M as well\n",
        "results_m_1_6 = []\n",
        "for obs in (([0, 2], [1]), ([0, 2], [1, 2])):\n",
        "    with m_1_6:\n",
        "        pm.set_data({'data1': obs[0], 'data2': obs[1]})\n",
        "        _trace_m_1_4 = pm.sample(2000, progressbar=False)\n",
        "    results_m_1_6.append([*obs, _trace_m_1_4['bag94_first'].mean()])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential sampling (2 chains in 1 job)\n",
            "BinaryGibbsMetropolis: [bag94_first]\n",
            "Sequential sampling (2 chains in 1 job)\n",
            "BinaryGibbsMetropolis: [bag94_first]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2a2ZEkhZg8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "326f2e0c-ded5-4629-dfe2-06f894db1df0"
      },
      "source": [
        "for r in results_m_1_6: print(r)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 2], [1], 0.0]\n",
            "[[0, 2], [1, 2], 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgt3gPWWWtzE",
        "colab_type": "text"
      },
      "source": [
        "## 1.7 The Monty Hall problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrdGgZbYBZSH",
        "colab_type": "code",
        "outputId": "1f5a0f76-64b7-4488-92fb-3b73edf25742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "with pm.Model() as m_1_7:\n",
        "    # Prior \n",
        "    door = pm.Categorical('door', np.ones(3)/3)\n",
        "\n",
        "    # Conditional probabality / Likelihood\n",
        "    p_doorB = pm.math.switch(tt.eq(door, 0), 1/2, \n",
        "                             (pm.math.switch(tt.eq(door, 1), 0, 1)))\n",
        "    doorB = pm.Bernoulli('door_B', p_doorB, observed=True)\n",
        "\n",
        "    trace_m_1_7 = pm.sample(200)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only 200 samples in chain.\n",
            "Sequential sampling (2 chains in 1 job)\n",
            "CategoricalGibbsMetropolis: [door]\n",
            "100%|██████████| 700/700 [00:00<00:00, 3977.36it/s]\n",
            "100%|██████████| 700/700 [00:00<00:00, 5045.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOl41qqYDgEk",
        "colab_type": "code",
        "outputId": "2a0730d5-0133-4157-8a4d-cc594e171a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(trace_m_1_7['door'] == 0).mean(), (trace_m_1_7['door'] == 2).mean(), 1/3, 2/3"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3375, 0.6625, 0.3333333333333333, 0.6666666666666666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}